{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9f99876e-1d61-4adb-9935-de9c1b06e77b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish connection\n",
    "storageAccountName = 'storagealfredspringboard'\n",
    "storageAccountAccessKey = 'MzzA3u+l/UnR40aPSEp5mLZTMPkt6bTmxxVMZYOSQfam+nm+es8Nya9lmK4k4lTUjB0g+gfSt43BFwf617brwQ=='\n",
    "blobContainerName = 'maincontainer'\n",
    "\n",
    "# Execute mount so that you can seamlessly access data without requiring credentials\n",
    "if not any(mount.mountPoint == '/mnt/FileStore/MountFolder/' for mount in dbutils.fs.mounts()):\n",
    "  try:\n",
    "    dbutils.fs.mount(\n",
    "    source = \"wasbs://{}@{}.blob.core.windows.net\".format(blobContainerName, storageAccountName),\n",
    "    mount_point = \"/mnt/FileStore/MountFolder/\",\n",
    "    extra_configs = {'fs.azure.account.key.' + storageAccountName + '.blob.core.windows.net': storageAccountAccessKey}\n",
    "  )\n",
    "  except Exception as e:\n",
    "    print(\"already mounted. Try to unmount first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "29b73860-6bec-4d13-a83b-c397b77457be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/FileStore/MountFolder/data/</td><td>data/</td><td>0</td></tr><tr><td>dbfs:/mnt/FileStore/MountFolder/data_model_planner.xlsx</td><td>data_model_planner.xlsx</td><td>3218963</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/FileStore/MountFolder/data/",
         "data/",
         0
        ],
        [
         "dbfs:/mnt/FileStore/MountFolder/data_model_planner.xlsx",
         "data_model_planner.xlsx",
         3218963
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create folder using command line in databricks\n",
    "dbutils.fs.mkdirs(\"dbfs:/mnt/FileStore/MountFolder/data\")\n",
    "\n",
    "# Display filepath to ensure mounting \n",
    "display(dbutils.fs.ls(\"dbfs:/mnt/FileStore/MountFolder/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2f778a6-716e-4551-baf3-a98b2d8568c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from enum import Enum\n",
    "import os\n",
    "import datetime\n",
    "import urllib.request\n",
    "\n",
    "# Sample/Full Extract Transform Load (ETL) toggle (True = pulls sample data and number sample lines (prototype), False = pull all data)\n",
    "SAMPLING = False\n",
    "SAMPLE_LINES = 5\n",
    "\n",
    "\n",
    "# Build Mapper\n",
    "#Create source variables to append to file paths\n",
    "class Source(Enum):\n",
    "    YELLOW = \"YELLOW\"\n",
    "    GREEN = \"GREEN\"\n",
    "    FHV = \"FHV\"\n",
    "    FHVHV = \"FHVHV\"\n",
    "\n",
    "#Establish base urls to scrape Tap/Source TLC Trip Record Data\n",
    "BASE_URLS = {\n",
    "    Source.YELLOW: \"https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_\",\n",
    "    Source.GREEN: \"https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_\",\n",
    "    Source.FHV: \"https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_\",\n",
    "    Source.FHVHV: \"https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_\",\n",
    "}\n",
    "\n",
    "#Establish file names to archive extracted data in Target location\n",
    "FILENAMES = {\n",
    "    Source.YELLOW: \"../data/sample_yellow_tripdata.csv\",\n",
    "    Source.GREEN: \"../data/sample_green_tripdata.csv\",\n",
    "    Source.FHV: \"../data/sample_fhv_tripdata.csv\",\n",
    "    Source.FHVHV: \"../data/sample_fhvhv_tripdata.csv\",\n",
    "}\n",
    "\n",
    "#Establish error logfiles (Success/Failure) to capture success (report of data collected) and failures (report of broken or error urls)\n",
    "SUCCESS_LOG = \"../data/log_success_file.txt\"\n",
    "FAILURE_LOG = \"../data/log_failure_file.txt\"\n",
    "\n",
    "#Establish each field name for every file type to validate against during the extraction (Big E) of ETL for each \"Tap\"/Source being pulled\n",
    "#target field: index in original file\n",
    "FIELD_MAPPING = {\n",
    "    Source.YELLOW: {\"vendor_name\": 0,\n",
    "                    \"Trip_Pickup_DateTime\": 1,\n",
    "                    \"Trip_Dropoff_DateTime\": 2,\n",
    "                    \"Passenger_Count\": 3,\n",
    "                    \"Trip_Distance\": 4,\n",
    "                    \"Start_Lon\": 5,\n",
    "                    \"Start_Lat\": 6,\n",
    "                    \"Rate_Code\": 7,\n",
    "                    \"store_and_forward\": 8,\n",
    "                    \"End_Lon\": 9,\n",
    "                    \"End_Lat\": 10,\n",
    "                    \"Payment_Type\": 11,\n",
    "                    \"Fare_Amt\": 12,\n",
    "                    \"surcharge\": 13,\n",
    "                    \"mta_tax\": 14,\n",
    "                    \"Tip_Amt\": 15,\n",
    "                    \"Tolls_Amt\": 16,\n",
    "                    \"Total_Amt\": 17\n",
    "                   },\n",
    "    Source.GREEN: {\"VendorID\": 0,\n",
    "                   \"lpep_pickup_datetime\": 1,\n",
    "                   \"Lpep_dropoff_datetime\": 2,\n",
    "                   \"Store_and_fwd_flag\": 3,\n",
    "                   \"RateCodeID\": 4,\n",
    "                   \"Pickup_longitude\": 5,\n",
    "                   \"Pickup_latitude\": 6,\n",
    "                   \"Dropoff_longitude\": 7,\n",
    "                   \"Dropoff_latitude\": 8,\n",
    "                   \"Passenger_count\": 9,\n",
    "                   \"Trip_distance\": 10,\n",
    "                   \"Fare_amount\": 11,\n",
    "                   \"Extra\": 12,\n",
    "                   \"MTA_tax\": 13,\n",
    "                   \"Tip_amount\": 14,\n",
    "                   \"Tolls_amount\": 15,\n",
    "                   \"Ehail_fee\": 16,\n",
    "                   \"Total_amount\": 17,\n",
    "                   \"Payment_type\": 18,\n",
    "                   \"Trip_type\": 19\n",
    "                  },\n",
    "\n",
    "    Source.FHV: {\"Dispatching_base_num\": 0,\n",
    "                 \"Pickup_date\": 1,\n",
    "                 \"locationID\":2\n",
    "                },\n",
    "    Source.FHVHV: {\"hvfhs_license_num\": 0,\n",
    "                   \"dispatching_base_num\": 1,\n",
    "                   \"pickup_datetime\": 2,\n",
    "                   \"dropoff_datetime\": 3,\n",
    "                   \"PULocationID\": 4,\n",
    "                   \"DOLocationID\": 5,\n",
    "                   \"SR_Flag\": 6\n",
    "                  }\n",
    "}\n",
    "\n",
    "#Define order of required fields in the transformed file\n",
    "#for each source type, define field order\n",
    "TRANSFORMED_FIELD_ORDER = {\n",
    "    Source.YELLOW: [\"vendor_name\",\n",
    "                    \"Trip_Pickup_DateTime\",\n",
    "                    \"Trip_Dropoff_DateTime\",\n",
    "                    \"Passenger_Count\",\n",
    "                    \"Trip_Distance\",\n",
    "                    \"Start_Lon\",\n",
    "                    \"Start_Lat\",\n",
    "                    \"Rate_Code\",\n",
    "                    \"store_and_forward\",\n",
    "                    \"End_Lon\",\n",
    "                    \"End_Lat\",\n",
    "                    \"Payment_Type\",\n",
    "                    \"Fare_Amt\",\n",
    "                    \"surcharge\",\n",
    "                    \"mta_tax\",\n",
    "                    \"Tip_Amt\",\n",
    "                    \"Tolls_Amt\",\n",
    "                    \"Total_Amt\",],\n",
    "    \n",
    "    Source.GREEN: [\"VendorID\",\n",
    "                   \"lpep_pickup_datetime\",\n",
    "                   \"Lpep_dropoff_datetime\",\n",
    "                   \"Store_and_fwd_flag\",\n",
    "                   \"RateCodeID\",\n",
    "                   \"Pickup_longitude\",\n",
    "                   \"Pickup_latitude\",\n",
    "                   \"Dropoff_longitude\",\n",
    "                   \"Dropoff_latitude\",\n",
    "                   \"Passenger_count\",\n",
    "                   \"Trip_distance\",\n",
    "                   \"Fare_amount\",\n",
    "                   \"Extra\",\n",
    "                   \"MTA_tax\",\n",
    "                   \"Tip_amount\",\n",
    "                   \"Tolls_amount\",\n",
    "                   \"Ehail_fee\",\n",
    "                   \"Total_amount\",\n",
    "                   \"Payment_type\",\n",
    "                   \"Trip_type\",],\n",
    "    \n",
    "    Source.FHV: [\"Dispatching_base_num\",\n",
    "                 \"Pickup_date\",\n",
    "                 \"locationID\"],\n",
    "    \n",
    "    Source.FHVHV: [\"hvfhs_license_num\",\n",
    "                    \"dispatching_base_num\",\n",
    "                    \"pickup_datetime\",\n",
    "                    \"dropoff_datetime\",\n",
    "                    \"PULocationID\",\n",
    "                    \"DOLocationID\",\n",
    "                    \"SR_Flag\"]\n",
    "                   }\n",
    "\n",
    "# This function returns a concatenated string: base_url+year+\"-\"+formatted_month+\".csv\"\n",
    "def _get_project_url(base_url, month, year):\n",
    "    formatted_month = \"{0:02d}\".format(month)\n",
    "    return f\"{base_url}{year}-{formatted_month}.csv\"\n",
    "\n",
    "\n",
    "def get_transformed_row(source_type, row):\n",
    "    try:\n",
    "        transformation_fields = TRANSFORMED_FIELD_ORDER[source_type]\n",
    "        mapper = FIELD_MAPPING[source_type]\n",
    "\n",
    "        return [row[mapper[field]] for field in transformation_fields]\n",
    "\n",
    "    except Exception as e:\n",
    "        if row != [\"\"]:\n",
    "            print(\"!\"*1000)\n",
    "            print(e)\n",
    "            print(row)\n",
    "        return None\n",
    "\n",
    "def _process_url(source_type, url, filename):\n",
    "    print(f\"Starting URL processing for {url} and {filename}\")\n",
    "    datasource = urllib.request.urlopen(url)\n",
    "\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    write_mode = \"a\" if file_exists else \"w\"\n",
    "    with open(filename, write_mode) as f, open(SUCCESS_LOG, \"a\") as success_f:\n",
    "        lines_from_datasource = [datasource.readline() for i in range(SAMPLE_LINES)]\n",
    "\n",
    "        for i, line in enumerate(lines_from_datasource):\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            if i == 0 and file_exists:\n",
    "                # if downloaded file exists skip header\n",
    "                # as you already have it from previous file\n",
    "                continue\n",
    "\n",
    "            row = line.decode(\"utf8\").rstrip().split(\",\")\n",
    "            transformed_row = get_transformed_row(source_type, row)\n",
    "            if not transformed_row: continue\n",
    "                \n",
    "            f.write(\",\".join(transformed_row) + \"\\n\")\n",
    "\n",
    "            if SAMPLING and i > SAMPLE_LINES:\n",
    "                break\n",
    "        success_f.write(f\"{url}\\n\")\n",
    "\n",
    "\n",
    "def _print_neat_error(err, month, year, url):\n",
    "    print(\n",
    "        f\"\"\"\n",
    "        {err}\\nThe above error occured for the following:\\n\n",
    "        URL: {url}\n",
    "        Month: {month}\n",
    "        Year: {year}\n",
    "        {_line_separator()}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def sync_files(month, year):\n",
    "    for source_type, base_url in BASE_URLS.items():\n",
    "        url = _get_project_url(base_url, month, year)\n",
    "        filename = FILENAMES[source_type]\n",
    "        try:\n",
    "            print(\"Calling process_url for \", url, filename)\n",
    "            _process_url(source_type, url, filename)\n",
    "        except Exception as e:\n",
    "            _print_neat_error(e, month, year, url)\n",
    "\n",
    "\n",
    "def _line_separator():\n",
    "    return \"=\" * 50\n",
    "\n",
    "\n",
    "def _banner():\n",
    "    return \"%s\\nWhole Data Overview\\n%s\" % ((_line_separator(),) * 2)\n",
    "\n",
    "\n",
    "def _greeting(day, month, year):\n",
    "    return f\"Starting program for {month}-{year}-{day}\\n\" + _line_separator()\n",
    "\n",
    "\n",
    "def run():\n",
    "    today = datetime.datetime.now()\n",
    "    current_day, current_month, current_year = today.day, today.month, today.year\n",
    "\n",
    "    print(_greeting(current_day, current_month, current_year))\n",
    "    print(_banner())\n",
    "\n",
    "    for year in range(2009, current_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            if (month, year) == (current_month, current_year):\n",
    "                return\n",
    "            sync_files(month, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "open_ended_capstone",
   "notebookOrigID": 796573160313166,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
