# Add Resource: Azure "fileshare storage"
--- Will utilize fileshare to storage to store loaded .csv files (ELT)
--- Save fileshare "(1) mount address", and "(2) username / (3) password" for mapping to VM later


# Add Resource: Configure Azure Virtual Machine (VM)
--- Will utilize vm to run python ELT code
--- Will utilize vm to extract and load big data into "fileshare storage" for transporting through Azure Data Factory and into DataBricks pipeline

Config:
--- Python (latest version)
--- VSCode (latest version)
--- Map network drive (manual)/(automatic through code: subprocess) using "(1) mount address", and "(2) username / (3) password"


# Test: Executed python code (ELT) to test if file is saved to new network drive


# Add Resource: Azure DataFactory Resource to move files within storage container
--- Create pipeline (Copy data)
--- Select source (new)
--- Create new linked service
--- tested connection
--- sink services to the main container

